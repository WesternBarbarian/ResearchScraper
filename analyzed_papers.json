{
  "metadata": {
    "exported_at": "2025-01-26T21:06:53.338819",
    "paper_count": 5,
    "min_relevance_score": 0.8,
    "export_format_version": "1.0"
  },
  "papers": [
    {
      "title": "Perceived Fairness of the Machine Learning Development Process: Concept\n  Scale Development",
      "authors": [
        "Anoop Mishra",
        "Deepak Khazanchi"
      ],
      "published": "2025-01-23T06:51:31Z",
      "summary": "In machine learning (ML) applications, unfairness is triggered due to bias in\nthe data, the data curation process, erroneous assumptions, and implicit bias\nrendered during the development process. It is also well-accepted by\nresearchers that fairness in ML application development is highly subjective,\nwith a lack of clarity of what it means from an ML development and\nimplementation perspective. Thus, in this research, we investigate and\nformalize the notion of the perceived fairness of ML development from a\nsociotechnical lens. Our goal in this research is to understand the\ncharacteristics of perceived fairness in ML applications. We address this\nresearch goal using a three-pronged strategy: 1) conducting virtual focus\ngroups with ML developers, 2) reviewing existing literature on fairness in ML,\nand 3) incorporating aspects of justice theory relating to procedural and\ndistributive justice. Based on our theoretical exposition, we propose\noperational attributes of perceived fairness to be transparency,\naccountability, and representativeness. These are described in terms of\nmultiple concepts that comprise each dimension of perceived fairness. We use\nthis operationalization to empirically validate the notion of perceived\nfairness of machine learning (ML) applications from both the ML practioners and\nusers perspectives. The multidimensional framework for perceived fairness\noffers a comprehensive understanding of perceived fairness, which can guide the\ncreation of fair ML systems with positive implications for society and\nbusinesses.",
      "link": "http://arxiv.org/abs/2501.13421v1",
      "categories": [
        "cs.HC",
        "cs.CY",
        "cs.LG",
        "J.4; J.1; K.4; K.6; I.2; E.m"
      ],
      "combination": "cs.CY AND cs.HC",
      "analysis": {
        "is_relevant": true,
        "relevance_score": 0.85,
        "practical_applications": "The paper discusses practical applications by offering a framework to embed fairness in ML system development, focusing on operational attributes of perceived fairness like transparency, accountability, and representativeness. This can be utilized by organizations to develop fairer ML applications that reduce bias and enhance ethical standards.",
        "thought_leadership_value": "The paper contributes significant thought leadership by formalizing the concept of perceived fairness in ML, bridging social concepts of justice with technical practices in ML development. It emphasizes the multi-dimensionality of fairness and provides a structured approach to integrating social considerations into technological practice, which are key to leading discourse on ethical AI.",
        "key_insights": [
          "Perceived fairness in ML is subjective and multifaceted, linking ML development to broader social justice concepts.",
          "A structured framework for fairness includes transparency, accountability, and representativeness, guiding the creation of fair ML systems.",
          "Engaging both ML practitioners and users' perspectives is critical to validating fairness in ML applications.",
          "Operationalizing fairness in ML requires consideration of socio-technical aspects, not just technical metrics."
        ]
      }
    },
    {
      "title": "Development of the Critical Reflection and Agency in Computing Index",
      "authors": [
        "Aadarsh Padiyath",
        "Mark Guzdial",
        "Barbara Ericson"
      ],
      "published": "2025-01-22T18:13:05Z",
      "summary": "As computing's societal impact grows, so does the need for computing students\nto recognize and address the ethical and sociotechnical implications of their\nwork. While there are efforts to integrate ethics into computing curricula, we\nlack a standardized tool to measure those efforts, specifically, students'\nattitudes towards ethical reflection and their ability to effect change. This\npaper introduces the novel framework of Critically Conscious Computing and\nreports on the development and content validation of the Critical Reflection\nand Agency in Computing Index, a novel instrument designed to assess\nundergraduate computing students' attitudes towards practicing critically\nconscious computing. The resulting index is a theoretically grounded,\nexpert-reviewed tool to support research and practice in computing ethics\neducation. This enables researchers and educators to gain insights into\nstudents' perspectives, inform the design of targeted ethics interventions, and\nmeasure the effectiveness of computing ethics education initiatives.",
      "link": "http://arxiv.org/abs/2501.13060v1",
      "categories": [
        "cs.CY",
        "cs.HC"
      ],
      "combination": "cs.CY AND cs.HC",
      "analysis": {
        "is_relevant": true,
        "relevance_score": 0.8,
        "practical_applications": "The paper's development of a standardized tool for measuring computing students' attitudes towards ethical reflection and agency is highly relevant for educational institutions and organizations interested in integrating and assessing computing ethics within their curricula. This can lead to more effective training programs that better prepare students to handle real-world ethical issues in AI development and implementation.",
        "thought_leadership_value": "This paper contributes to thought leadership by establishing a novel framework, Critically Conscious Computing, which challenges current norms by emphasizing the importance of ethical and sociotechnical awareness in computing education. It pushes the discourse on ethics in AI and computing to focus more on student attitudes and capabilities, providing a new angle from which to approach ethics integration in technology fields.",
        "key_insights": [
          "The introduction of the Critical Reflection and Agency in Computing Index is a significant step in measuring and understanding the efficacy of ethics education in computing fields.",
          "Standardizing the measurement of students' ethical perspectives can lead to better targeted and more effective interventions in computing education.",
          "The paper highlights the importance of developing students' critical consciousness in computing, implying a need for ongoing evolution of educational practices to meet societal and ethical demands in AI and technology."
        ]
      }
    },
    {
      "title": "Designing and Evaluating an Educational Recommender System with\n  Different Levels of User Control",
      "authors": [
        "Qurat Ul Ain",
        "Mohamed Amine Chatti",
        "William Kana Tsoplefack",
        "Rawaa Alatrash",
        "Shoeb Joarder"
      ],
      "published": "2025-01-22T14:14:49Z",
      "summary": "Educational recommender systems (ERSs) play a crucial role in personalizing\nlearning experiences and enhancing educational outcomes by providing\nrecommendations of personalized resources and activities to learners, tailored\nto their individual learning needs. However, their effectiveness is often\ndiminished by insufficient user control and limited transparency. To address\nthese challenges, in this paper, we present the systematic design and\nevaluation of an interactive ERS, in which we introduce different levels of\nuser control. Concretely, we introduce user control around the input (i.e.,\nuser profile), process (i.e., recommendation algorithm), and output (i.e.,\nrecommendations) of the ERS. To evaluate our system, we conducted an online\nuser study (N=30) to explore the impact of user control on users' perceptions\nof the ERS in terms of several important user-centric aspects. Moreover, we\ninvestigated the effects of user control on multiple recommendation goals,\nnamely transparency, trust, and satisfaction, as well as the interactions\nbetween these goals. Our results demonstrate the positive impact of user\ncontrol on user perceived benefits of the ERS. Moreover, our study shows that\nuser control strongly correlates with transparency and moderately correlates\nwith trust and satisfaction. In terms of interaction between these goals, our\nresults reveal that transparency moderately correlates and trust strongly\ncorrelates with satisfaction. Whereas, transparency and trust stand out as less\ncorrelated with each other.",
      "link": "http://arxiv.org/abs/2501.12894v1",
      "categories": [
        "cs.IR",
        "cs.CY",
        "cs.HC"
      ],
      "combination": "cs.CY AND cs.HC",
      "analysis": {
        "is_relevant": true,
        "relevance_score": 0.9,
        "practical_applications": "The paper discusses the development and evaluation of an educational recommender system with enhanced user control, which is highly relevant for institutions aiming to improve personalized learning experiences. By focusing on user control, this approach can be applied in the design of educational technologies to increase user engagement, transparency, and satisfaction.",
        "thought_leadership_value": "This paper provides valuable insights into the role of user control in educational technologies, potentially influencing how AI systems are designed for personal interaction and user satisfaction. It contributes to the discourse on transparent AI systems and the importance of user agency in automated processes, promoting an understanding of how these elements impact trust and satisfaction.",
        "key_insights": [
          "User control is a critical factor that enhances the perceived benefits of educational recommender systems, particularly impacting transparency and satisfaction.",
          "Increasing levels of user control correlates moderately with trust and strongly with satisfaction, emphasizing the need for interactive and user-centric design in AI applications.",
          "The study model illustrates interactions between transparency, trust, and satisfaction, highlighting the complex relationships between these goals in user-centric system design."
        ]
      }
    },
    {
      "title": "Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at\n  CHI through a Systematic Literature Review",
      "authors": [
        "Rock Yuren Pang",
        "Hope Schroeder",
        "Kynnedy Simone Smith",
        "Solon Barocas",
        "Ziang Xiao",
        "Emily Tseng",
        "Danielle Bragg"
      ],
      "published": "2025-01-22T00:31:51Z",
      "summary": "Large language models (LLMs) have been positioned to revolutionize HCI, by\nreshaping not only the interfaces, design patterns, and sociotechnical systems\nthat we study, but also the research practices we use. To-date, however, there\nhas been little understanding of LLMs' uptake in HCI. We address this gap via a\nsystematic literature review of 153 CHI papers from 2020-24 that engage with\nLLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in\nHCI projects; (3) contribution types; and (4) acknowledged limitations and\nrisks. We find LLM work in 10 diverse domains, primarily via empirical and\nartifact contributions. Authors use LLMs in five distinct roles, including as\nresearch tools or simulated users. Still, authors often raise validity and\nreproducibility concerns, and overwhelmingly study closed models. We outline\nopportunities to improve HCI research with and on LLMs, and provide guiding\nquestions for researchers to consider the validity and appropriateness of\nLLM-related work.",
      "link": "http://arxiv.org/abs/2501.12557v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "combination": "cs.CY AND cs.HC",
      "analysis": {
        "is_relevant": true,
        "relevance_score": 0.85,
        "practical_applications": "The paper provides a comprehensive taxonomy of how large language models (LLMs) are currently being utilized in the field of human-computer interaction (HCI), which is vital for understanding how these models can be applied effectively. By identifying domains, roles, and contribution types, it paves the way for developing more targeted and innovative applications of LLMs in various HCI subfields.",
        "thought_leadership_value": "This paper contributes to thought leadership by systematically analyzing the integration of LLMs into HCI, highlighting both the current landscape and unexplored opportunities. Its critical evaluation of the validity, reproducibility, and limitations of existing research sets a groundwork for a more responsible and forward-looking adoption of AI in HCI.",
        "key_insights": [
          "LLMs are employed in diverse roles within HCI, such as research tools and simulated users, highlighting their versatility.",
          "The paper identifies 10 different domains within CHI where LLMs have been applied, suggesting promising areas for future research and application.",
          "Validity and reproducibility are major challenges acknowledged in current LLM-related research, emphasizing the need for more robust methodologies.",
          "Most studies scrutinized involve closed models, indicating a possible limitation in transparency and accessibility.",
          "The authors provide guiding questions to enhance the rigor and ethical consideration of research utilizing LLMs, offering a framework for future studies."
        ]
      }
    },
    {
      "title": "Expertise elevates AI usage: experimental evidence comparing laypeople\n  and professional artists",
      "authors": [
        "Thomas F. Eisenmann",
        "Andres Karjus",
        "Mar Canet Sola",
        "Levin Brinkmann",
        "Bramantyo Ibrahim Supriyatno",
        "Iyad Rahwan"
      ],
      "published": "2025-01-21T18:53:21Z",
      "summary": "Novel capacities of generative AI to analyze and generate cultural artifacts\nraise inevitable questions about the nature and value of artistic education and\nhuman expertise. Has AI already leveled the playing field between professional\nartists and laypeople, or do trained artistic expressive capacity, curation\nskills and experience instead enhance the ability to use these new tools? In\nthis pre-registered study, we conduct experimental comparisons between 50\nactive artists and a demographically matched sample of laypeople. We designed\ntwo tasks to approximate artistic practice for testing their capabilities in\nboth faithful and creative image creation: replicating a reference image, and\nmoving as far away as possible from it. We developed a bespoke platform where\nparticipants used a modern text-to-image model to complete both tasks. We also\ncollected and compared participants' sentiments towards AI. On average, artists\nproduced more faithful and creative outputs than their lay counterparts,\nalthough only by a small margin. While AI may ease content creation,\nprofessional expertise is still valuable - even within the confined space of\ngenerative AI itself. Finally, we also explored how well an exemplary\nvision-capable large language model (GPT-4o) would complete the same tasks, if\ngiven the role of an image generation agent, and found it performed on par in\ncopying but outperformed even artists in the creative task. The very best\nresults were still produced by humans in both tasks. These outcomes highlight\nthe importance of integrating artistic skills with AI training to prepare\nartists and other visual professionals for a technologically evolving\nlandscape. We see a potential in collaborative synergy with generative AI,\nwhich could reshape creative industries and education in the arts.",
      "link": "http://arxiv.org/abs/2501.12374v1",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "combination": "cs.CY AND cs.HC",
      "analysis": {
        "is_relevant": true,
        "relevance_score": 0.85,
        "practical_applications": "The paper suggests that while AI can facilitate content creation, human expertise in artistic fields is still crucial. This implies potential applications in the creative industries where AI and human collaboration could enhance artistic outputs in areas like digital art, graphic design, or media production.",
        "thought_leadership_value": "The study highlights the ongoing value of human expertise even in an AI-dominated creative process, suggesting that AI should be seen as a complement rather than a replacement. This perspective is valuable for guiding creative industries through technological transitions and for informing educational programs aimed at preparing artists for the future.",
        "key_insights": [
          "Human expertise continues to enhance AI-generated outputs, indicating the importance of skilled artists in AI-driven environments.",
          "The study provides experimental evidence that while AI can outperform humans in certain creative aspects, the best results still involve human input.",
          "There is a potential for collaborative synergy between artists and AI, suggesting a future for hybrid creative processes.",
          "Artists' ability to faithfully and creatively interpret AI-generated content remains superior, even if only marginally, underscoring the need for integrating AI into traditional artistic training."
        ]
      }
    }
  ]
}